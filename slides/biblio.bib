@book{SuttonBarto,
  author    = {Richard S. Sutton and Andrew G. Barto},
  title     = {Reinforcement Learning: An Introduction},
  year      = {2018},
  publisher = {MIT Press},
  address   = {Cambridge, Massachusetts (MA)},
  %url       = {http://incompleteideas.net/book/the-book.html}
}

@InCollection{Spaan12pomdp,
  author =       {Matthijs T. J. Spaan},
  title =        {Partially Observable Markov Decision Processes},
  booktitle =    {Reinforcement Learning: State of the Art},
  publisher =    {Springer Verlag},
  year =         2012,
  editor =       {Marco Wiering and Martijn van Otterlo},
  pages =        {387--414}
}

% @book{BellmanDP,
%   title     = {Dynamic Programming},
%   author    = {Richard E. Bellman},
%   publisher = {Princeton University Press},
%   isbn      = {0-691-07951-X},
%   year      = {1957},
%   series    = {Princeton Landmarks in Mathematics and Physics},
%   edition   = {},
%   volume    = {}
% }

@InCollection{Peters2010,
  author    = {Peters, Jan and Bagnell, J. Andrew},
  title     = {Policy Gradient Methods},
  editor    = {Sammut, Claude and Webb, Geoffrey I.},
  booktitle = {Encyclopedia of Machine Learning},
  year      = {2010},
  publisher = {Springer US},
  address   = {Boston, MA},
  pages     = {774--776},
  isbn      = {978-0-387-30164-8}
}

@inproceedings{Aberdeen2002ScalingIP,
  title     = {Scaling Internal-State Policy-Gradient Methods for POMDPs},
  author    = {D. Aberdeen and Jonathan Baxter},
  year      = {2002},
  booktitle = {International Conference on Machine Learning}
}